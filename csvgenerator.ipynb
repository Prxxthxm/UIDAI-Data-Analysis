{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a40a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation complete\n",
      "  pincode  people\n",
      "0  100000     220\n",
      "1  110001    5592\n",
      "2  110002   11061\n",
      "3  110003    9920\n",
      "4  110004     178\n",
      "Total pincodes: 19815\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# combining the given csv to make one compiled csv with sum of columns as populations for each PIN code\n",
    "BIO_COLS   = [\"bio_age_5_17\", \"bio_age_17_\"]\n",
    "DEMO_COLS  = [\"demo_age_5_17\", \"demo_age_17_\"]\n",
    "ENROL_COLS = [\"age_0_5\", \"age_5_17\", \"age_18_greater\"]\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for file in glob.glob(os.path.join(DATA_DIR, \"*.csv\")):\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    pin_col = None\n",
    "    for c in df.columns:\n",
    "        if \"pin\" in c.lower():\n",
    "            pin_col = c\n",
    "            break\n",
    "\n",
    "    if pin_col is None:\n",
    "        print(f\"No pincode column found in {file}\")\n",
    "        continue\n",
    "\n",
    "    if set(BIO_COLS).issubset(df.columns):\n",
    "        people = df[BIO_COLS].sum(axis=1)\n",
    "\n",
    "    elif set(DEMO_COLS).issubset(df.columns):\n",
    "        people = df[DEMO_COLS].sum(axis=1)\n",
    "\n",
    "    elif set(ENROL_COLS).issubset(df.columns):\n",
    "        people = df[ENROL_COLS].sum(axis=1)\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown format: {file}\")\n",
    "        continue\n",
    "\n",
    "    temp = pd.DataFrame({\n",
    "        \"pincode\": df[pin_col],\n",
    "        \"people\": people\n",
    "    })\n",
    "\n",
    "    all_rows.append(temp)\n",
    "\n",
    "# combining everything\n",
    "master = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# cleaning data\n",
    "master[\"pincode\"] = master[\"pincode\"].astype(str).str.zfill(6)\n",
    "master[\"people\"] = pd.to_numeric(master[\"people\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# final compiled df\n",
    "final = master.groupby(\"pincode\", as_index=False)[\"people\"].sum()\n",
    "\n",
    "print(\"Compilation complete\")\n",
    "print(final.head())\n",
    "print(f\"Total pincodes: {len(final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b06ce2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved to output/india_pincode_heatmap.html\n"
     ]
    }
   ],
   "source": [
    "import pgeocode\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# geocode pincodes\n",
    "nomi = pgeocode.Nominatim(\"IN\")\n",
    "geo = nomi.query_postal_code(final[\"pincode\"].tolist())\n",
    "\n",
    "final[\"lat\"] = geo.latitude.values\n",
    "final[\"lon\"] = geo.longitude.values\n",
    "\n",
    "# dropping invalid locations\n",
    "final = final.dropna(subset=[\"lat\", \"lon\"])\n",
    "\n",
    "# heatmap data: [lat, lon, weight]\n",
    "heat_data = final[[\"lat\", \"lon\", \"people\"]].values.tolist()\n",
    "\n",
    "# creating india map\n",
    "m = folium.Map(location=[22.0, 80.0], zoom_start=5)\n",
    "\n",
    "HeatMap(\n",
    "    heat_data,\n",
    "    radius=14,\n",
    "    blur=20,\n",
    "    max_zoom=8\n",
    ").add_to(m)\n",
    "\n",
    "# creating output directory if it doesn't exist\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "m.save(\"output/india_pincode_heatmap.html\")\n",
    "\n",
    "print(\"Heatmap saved to output/india_pincode_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f656b5",
   "metadata": {},
   "source": [
    "We are collecting data for aadhar centers from UIDAI website. We have only taken a small amount so as to not over load the official website with needless requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9da83352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PINs to fetch: 400\n",
      "Already processed: 400\n",
      "Remaining: 0\n",
      "\n",
      "✅ Finished fetching center counts for subset\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "API_URL = \"https://bhuvan-app3.nrsc.gov.in/aadhaar/usrtask/app_specific/get/getpinDetails.php\"\n",
    "\n",
    "OUTPUT_FILE = \"pincode_center_counts_subset.csv\"\n",
    "\n",
    "SLEEP_TIME = 0.35\n",
    "SAVE_EVERY = 100\n",
    "\n",
    "def print_progress(current, total, start_time):\n",
    "    bar_length = 30\n",
    "    progress = current / total\n",
    "    filled = int(bar_length * progress)\n",
    "    bar = \"█\" * filled + \"-\" * (bar_length - filled)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = elapsed / current if current > 0 else 0\n",
    "    remaining = rate * (total - current)\n",
    "\n",
    "    mins, secs = divmod(int(remaining), 60)\n",
    "    hrs, mins = divmod(mins, 60)\n",
    "\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {progress*100:5.1f}% \"\n",
    "        f\"| {current}/{total} \"\n",
    "        f\"| ETA: {hrs:02d}:{mins:02d}:{secs:02d}\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ensuring correct dtypes\n",
    "final[\"pincode\"] = final[\"pincode\"].astype(str)\n",
    "final[\"people\"] = pd.to_numeric(final[\"people\"], errors=\"coerce\")\n",
    "\n",
    "# sorting by population descending\n",
    "final_sorted = final.sort_values(\n",
    "    by=\"people\",\n",
    "    ascending=False,\n",
    "    na_position=\"last\"\n",
    ")\n",
    "\n",
    "# selecting aadhar centers of interest\n",
    "subset_10000_10200 = final_sorted.iloc[10000:10200]\n",
    "top_200 = final_sorted.head(200)\n",
    "\n",
    "# combining the df\n",
    "final_subset = pd.concat([top_200, subset_10000_10200], ignore_index=True)\n",
    "\n",
    "pincodes = final_subset[\"pincode\"].unique()\n",
    "total_pins = len(pincodes)\n",
    "\n",
    "print(\"Total PINs to fetch:\", total_pins)\n",
    "\n",
    "# resume support\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    df_done = pd.read_csv(OUTPUT_FILE)\n",
    "    df_done[\"pincode\"] = df_done[\"pincode\"].astype(str)\n",
    "    done_pins = set(df_done[\"pincode\"])\n",
    "else:\n",
    "    df_done = pd.DataFrame(columns=[\"pincode\", \"center_count\"])\n",
    "    done_pins = set()\n",
    "\n",
    "print(\"Already processed:\", len(done_pins))\n",
    "print(\"Remaining:\", total_pins - len(done_pins))\n",
    "\n",
    "results_buffer = []\n",
    "processed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for pin in pincodes:\n",
    "    if pin in done_pins:\n",
    "        processed += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        params = {\n",
    "            \"sno\": pin,\n",
    "            \"str\": \"\"\n",
    "        }\n",
    "\n",
    "        r = requests.get(API_URL, params=params, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        center_count = data.get(\"centerCount\", 0)\n",
    "\n",
    "        results_buffer.append({\n",
    "            \"pincode\": pin,\n",
    "            \"center_count\": center_count\n",
    "        })\n",
    "\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "    except Exception:\n",
    "        results_buffer.append({\n",
    "            \"pincode\": pin,\n",
    "            \"center_count\": None\n",
    "        })\n",
    "\n",
    "    processed += 1\n",
    "    print_progress(processed, total_pins, start_time)\n",
    "\n",
    "    if len(results_buffer) >= SAVE_EVERY:\n",
    "        df_done = pd.concat(\n",
    "            [df_done, pd.DataFrame(results_buffer)],\n",
    "            ignore_index=True\n",
    "        )\n",
    "        df_done.to_csv(OUTPUT_FILE, index=False)\n",
    "        results_buffer.clear()\n",
    "\n",
    "# final save\n",
    "if results_buffer:\n",
    "    df_done = pd.concat(\n",
    "        [df_done, pd.DataFrame(results_buffer)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df_done.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"\\n✅ Finished fetching center counts for subset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4f72c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pincode  people        lat        lon\n",
      "92    110094  190580  28.663867  77.227767\n",
      "2694  244001  189541  28.864100  78.826653\n",
      "58    110059  183169  28.655300  77.065700\n",
      "1648  202001  152776  27.916500  78.064556\n",
      "2868  247001  147476  29.949038  77.544543\n"
     ]
    }
   ],
   "source": [
    "final_sorted_by_people = final.sort_values(by=\"people\", ascending=False)\n",
    "print(final_sorted_by_people.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829e3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
